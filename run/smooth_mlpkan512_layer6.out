nohup: ignoring input
/home/fengw666/.conda/envs/torch_radon/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
begin to read data
Data Loading with 9.560 s
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
deeponet                                 --
├─FNN: 1-1                               --
│    └─SiLU: 2-1                         --
│    └─KAN: 2-2                          --
│    │    └─GELU: 3-1                    --
│    │    └─ParameterList: 3-2           2,098,176
│    │    └─ParameterList: 3-3           16,785,408
│    │    └─ModuleList: 3-4              9,216
│    │    └─ModuleList: 3-5              2
├─FNO2d: 1-2                             --
│    └─GELU: 2-3                         --
│    └─Linear: 2-4                       64
│    └─ModuleList: 2-5                   --
│    │    └─SpectralConv2d: 3-6          663,552
│    │    └─SpectralConv2d: 3-7          663,552
│    │    └─SpectralConv2d: 3-8          663,552
│    │    └─SpectralConv2d: 3-9          663,552
│    │    └─SpectralConv2d: 3-10         663,552
│    │    └─SpectralConv2d: 3-11         663,552
│    └─ModuleList: 2-6                   --
│    │    └─Conv2d: 3-12                 1,056
│    │    └─Conv2d: 3-13                 1,056
│    │    └─Conv2d: 3-14                 1,056
│    │    └─Conv2d: 3-15                 1,056
│    │    └─Conv2d: 3-16                 1,056
│    │    └─Conv2d: 3-17                 1,056
│    └─Linear: 2-7                       4,224
│    └─Linear: 2-8                       516
=================================================================
Total params: 22,885,254
Trainable params: 22,885,254
Non-trainable params: 0
=================================================================
Training...
0 198.0426416248083 1.059443112373352 0.05137219031651815
1 200.5182276275009 0.2111722087542216 0.02935412613550822
2 201.5615065228194 0.14885152661005657 0.022092255075772605
3 202.78613481856883 0.11849677549997965 0.01852101441224416
4 202.10297094658017 0.10110315809249878 0.015949661016464233
5 201.67733850330114 0.086526833375295 0.014346108317375183
6 201.52438242547214 0.07786179313659668 0.013638213892777761
7 203.19206745922565 0.07174497768084208 0.011926838338375092
8 201.83904780820012 0.0669136246840159 0.012036975642045339
9 200.00703881122172 0.06172009563446045 0.010841790616512298
10 199.6715110503137 0.059443825340271 0.010326850354671478
11 199.15916627459228 0.05715589464505513 0.010163170218467712
12 200.79020299948752 0.05236915752092997 0.010632661630709967
13 200.17573366686702 0.051299861113230386 0.008534102906783423
14 200.89094150997698 0.0481250271320343 0.009093191663424174
15 201.74265436828136 0.04760348602930705 0.00872193479537964
16 201.67311079986393 0.045525162967046104 0.008422256916761399
17 202.77040141262114 0.044477627929051716 0.007892320195833842
18 201.7891130167991 0.04136427349249522 0.0077202094495296475
19 201.57873778790236 0.041142605622609456 0.008150642683108647
20 201.78782057389617 0.04200211715698242 0.007194391816854477
21 200.9554609451443 0.03904946681658427 0.006985536535580953
22 199.61724920384586 0.03974251442750295 0.0074770363469918565
23 199.099326049909 0.03666986084779104 0.0065446241597334545
24 200.9310426171869 0.03660101899305979 0.0069892780184745784
25 199.98766158521175 0.035449155759811404 0.007306952665249507
26 199.8864297941327 0.03411487347284953 0.00674937371412913
27 203.26773435249925 0.033520346935590105 0.006844940662384033
28 205.11754393950105 0.034045061286290486 0.006903977523247401
29 205.0476357359439 0.032519872252146406 0.0068445670207341516
30 205.11297236941755 0.03180874547163645 0.006562858055035274
31 205.00060266815126 0.031174026727676392 0.006101488222678503
32 204.98625004291534 0.03205644536018372 0.005926084409157435
33 204.87925082072616 0.030559427897135418 0.006413747588793437
34 204.374241579324 0.029339470982551574 0.005518734107414882
35 203.44425412267447 0.029076474372545878 0.005720207909742991
36 203.4719223510474 0.029819380362828572 0.005830858071645101
37 203.54344503954053 0.029455963182449342 0.005408384501934051
38 203.5708780735731 0.02782176590760549 0.0055715007235606516
39 203.70561783015728 0.027262180463473003 0.005204460283120473
40 204.66541837714612 0.027826432100931803 0.005525245676438014
41 204.99488887935877 0.026629441952705384 0.005076398054758707
42 204.95159648358822 0.025187856872876484 0.005137091447909673
43 204.97226135991514 0.026105801320075988 0.005550751080115636
44 205.03341274522245 0.025564921776453652 0.006694537202517192
45 205.0197663716972 0.025366336743036906 0.005508502458532651
46 205.09716648608446 0.02574471465746562 0.0051512906004985174
47 203.76520304009318 0.024520807456970214 0.0048558006832997
48 203.56901115365326 0.024846878441174825 0.005589203248421351
49 203.58155355602503 0.025400881632169088 0.0049545630067586895
50 203.6348708216101 0.024248366951942445 0.005198830107847849
51 203.68355328962207 0.024243132241566975 0.004808882281184196
52 203.60702511109412 0.023411936322848003 0.00481350114941597
53 204.38796321302652 0.02259238659143448 0.004859111254413922
54 205.05928255990148 0.022807948625087737 0.00522868254284064
55 205.20572602562606 0.022889988601207733 0.005214546735088031
56 205.06171256303787 0.023216983433564504 0.004842276160915693
57 205.09148040041327 0.02240331999063492 0.005153316602110863
58 205.02274730987847 0.02183122692902883 0.005021394108732541
59 205.06707631237805 0.022384215720494587 0.004781167988975842
60 205.08624072372913 0.021846898607412974 0.004556015759706497
61 205.06177271530032 0.021787175782521567 0.004709036111831665
62 204.00764218904078 0.021608993144830068 0.004445142621795337
63 203.6503330245614 0.021585145501295727 0.004274562731385231
64 203.54538605734706 0.020592319456736247 0.004525833820303281
65 203.6795936767012 0.020933792293071747 0.004548723056912422
66 203.7375220246613 0.020110081164042153 0.004653584837913513
67 204.71755545586348 0.020912003417809803 0.004373547911643982
68 205.06392474099994 0.02024155328273773 0.004705067550142606
69 204.90453239157796 0.020722512753804524 0.004350561623771986
70 205.13816414028406 0.020130060827732086 0.004320623323321343
71 205.09201186522841 0.019421007124582928 0.0049298434207836785
72 205.05266835168004 0.020515050971508027 0.005274592950940132
73 204.93518827855587 0.01874569497903188 0.0042945746431748075
Early stop at epoch 74
Training Time:15252.695s
