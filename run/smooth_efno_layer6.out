nohup: ignoring input
begin to read data
Data Loading with 9.242 s
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
deeponet                                 --
├─FNN: 1-1                               --
│    └─Tanh: 2-1                         --
│    └─ModuleList: 2-2                   --
│    │    └─Linear: 3-1                  384
│    │    └─Linear: 3-2                  16,512
│    │    └─Linear: 3-3                  16,512
│    │    └─Linear: 3-4                  528,384
│    └─ModuleList: 2-3                   --
│    │    └─BatchNorm1d: 3-5             256
│    │    └─BatchNorm1d: 3-6             256
│    │    └─BatchNorm1d: 3-7             256
│    │    └─BatchNorm1d: 3-8             8,192
├─FNO2d: 1-2                             --
│    └─GELU: 2-4                         --
│    └─Linear: 2-5                       64
│    └─ModuleList: 2-6                   --
│    │    └─SpectralConv2d: 3-9          663,552
│    │    └─SpectralConv2d: 3-10         663,552
│    │    └─SpectralConv2d: 3-11         663,552
│    │    └─SpectralConv2d: 3-12         663,552
│    │    └─SpectralConv2d: 3-13         663,552
│    │    └─SpectralConv2d: 3-14         663,552
│    └─ModuleList: 2-7                   --
│    │    └─Conv2d: 3-15                 1,056
│    │    └─Conv2d: 3-16                 1,056
│    │    └─Conv2d: 3-17                 1,056
│    │    └─Conv2d: 3-18                 1,056
│    │    └─Conv2d: 3-19                 1,056
│    │    └─Conv2d: 3-20                 1,056
│    └─Linear: 2-8                       4,224
│    └─Linear: 2-9                       516
=================================================================
Total params: 4,563,204
Trainable params: 4,563,204
Non-trainable params: 0
=================================================================
Training...
0 93.00207502394915 0.5869739356994629 0.05577379703521729
1 95.10146925225854 0.2354570737838745 0.0378342878818512
2 95.17072115465999 0.18249131781260172 0.0303049898147583
3 92.4587755035609 0.15356897808710734 0.026285935640335083
4 91.6446040160954 0.1347736255645752 0.02344200849533081
5 91.46769685670733 0.11998173243204753 0.023281112909317017
6 91.52551916614175 0.11062201484044393 0.02004083037376404
7 91.44651588052511 0.10400451539357504 0.0178731769323349
8 91.55705723911524 0.09630172306696574 0.017219337224960326
9 91.45713698677719 0.0890932055314382 0.015395281314849853
10 91.57213893905282 0.08589375727971395 0.015034504532814026
11 91.43831715546548 0.08148685452143352 0.014996588230133057
12 91.556390915066 0.07981628098487854 0.014395232796669006
13 91.52573282457888 0.07564428733189901 0.01397934854030609
14 91.48172787204385 0.07240038498242696 0.013023889660835265
15 91.55385073833168 0.16030948209762574 0.016099880933761596
16 91.49083713069558 0.07345216910044353 0.012935087084770203
17 91.56444948911667 0.06619478044509888 0.012787594199180604
18 91.48126352764666 0.06624557150204977 0.011955567598342896
19 91.54240124300122 0.06366457131703694 0.012014421224594117
20 91.58312243968248 0.06207883812586466 0.011684086322784424
21 91.48027302138507 0.06112101902961731 0.011626037955284118
22 91.54968696087599 0.05941089989344279 0.011063039302825928
23 91.49217364937067 0.05904121150970459 0.01193283498287201
24 91.56216141581535 0.05875803149541219 0.011121469736099242
25 91.4710608329624 0.056240505266189574 0.010760189294815063
26 91.55841269530356 0.055441930802663165 0.010583099722862244
27 91.46660379692912 0.05446276108423869 0.010585241317749024
28 91.55705527216196 0.053500395981470744 0.010395591855049133
29 91.53943862952292 0.0536895143032074 0.010505536198616027
30 91.5267664398998 0.14430183701515198 0.020213146209716797
31 91.52754480391741 0.06427409904797872 0.010082347989082337
32 91.46329512447119 0.04878711446126302 0.009255421459674834
33 91.56061048060656 0.047115154520670575 0.009314915835857392
34 91.45045537687838 0.04697551441192627 0.00899671196937561
35 91.52888202853501 0.04771094808578491 0.009397015869617463
36 91.51771634072065 0.04648486626942953 0.009464019536972046
37 91.45399063080549 0.04777626363436381 0.009902660250663758
38 91.49872422963381 0.045736757739384966 0.009209642708301545
39 91.44078853167593 0.046389248164494835 0.0089752596616745
40 91.55286061018705 0.04603738090197245 0.009227371215820313
41 91.43001450784504 0.04544311243693034 0.009025623798370361
42 91.49955006875098 0.04506960860093435 0.00884076178073883
43 91.48912962898612 0.04432280314763387 0.008748423755168915
44 91.4122284501791 0.044328960156440736 0.009398676455020905
45 91.50564830005169 0.06181530552705129 0.00891041785478592
46 91.41736162826419 0.03833075771331787 0.008367266952991486
47 91.50104982033372 0.039145167104403175 0.00832418292760849
48 91.44813845865428 0.040370257425308226 0.008304132223129273
49 91.54254835285246 0.03995411519209544 0.00795199304819107
50 91.50345127657056 0.040514872845013934 0.008359026610851288
51 91.56052367947996 0.03953684560457865 0.008192818462848663
52 91.53934530541301 0.0401779149611791 0.008310861885547638
53 91.48794260434806 0.04049295260111491 0.008077980577945709
54 91.56107941269875 0.03984358553091685 0.008165041208267212
55 91.47560422681272 0.0485232782681783 0.0872294044494629
56 91.57142166979611 0.11827722959518433 0.008339086771011353
57 91.5021727643907 0.03737437714735667 0.0075510874390602115
58 91.56220894120634 0.036334211858113606 0.007258621752262115
59 91.53340483270586 0.036136441842714945 0.007645539045333862
60 91.6273341961205 0.03653713038762411 0.007414312958717346
61 91.54565566405654 0.03737720096111297 0.007346418499946594
62 91.64636669307947 0.03689141363302867 0.007254028022289276
63 91.508794112131 0.036917979574203494 0.0074657672643661495
64 91.60797653347254 0.037357748341560366 0.008146139979362487
65 91.53716504760087 0.03791709304650625 0.0076402205228805545
66 91.59481867402792 0.03616405278046926 0.007546948492527008
67 91.60663044638932 0.03652395293712616 0.0073748365044593815
68 91.54519520886242 0.036473511028289794 0.00732960432767868
69 91.65139956399798 0.036538333423932395 0.007109864354133606
70 91.54710601456463 0.03678655384381612 0.007172883152961731
71 91.57400935329497 0.03558978555997213 0.007231869995594025
72 91.48449498228729 0.03556193922360738 0.007398932576179505
73 91.57417464442551 0.0347659473657608 0.007232185900211335
74 91.46511779353023 0.03402624873320262 0.007274248898029328
75 91.56470915675163 0.03531062990029653 0.007389386594295502
76 91.46407795324922 0.034399583156903585 0.007217082679271698
77 91.56520590558648 0.09256056731541952 0.007536894679069519
78 91.86087097041309 0.033783671593666076 0.006928319036960602
79 92.81856279633939 0.03209879369735718 0.006672137379646301
80 93.60129811242223 0.03307276854515076 0.006882585287094116
81 93.63060643710196 0.03228439462979635 0.006723641157150268
82 93.82715996727347 0.032712396081288654 0.006888422071933746
83 93.78897228650749 0.0321790879646937 0.007384189963340759
84 93.75973630137742 0.03361153167088826 0.006668095886707306
85 93.78510818071663 0.03234864387512207 0.007130199372768402
86 93.69062802009284 0.0329023750782013 0.006818227469921112
87 93.81932532601058 0.03389946866035461 0.00682944118976593
88 93.79453660920262 0.0326466681877772 0.006851183772087097
89 93.72614207677543 0.03285881644090017 0.0067628213763237
90 93.84228088892996 0.032269825514157614 0.006536460220813751
91 93.68708227388561 0.032299119353294374 0.006961116790771485
92 93.78624762222171 0.032978368759155274 0.006297303438186646
93 93.67965964972973 0.03186879223982493 0.006460419297218323
94 93.71939591877162 0.058265361841519675 0.005939472615718842
95 94.02014569565654 0.026099433851242065 0.005917938947677612
96 93.60418845154345 0.026706193923950194 0.006084211766719818
97 93.63853752054274 0.027649695865313212 0.006089053153991699/home/fengw666/.conda/envs/torch_radon/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

98 93.61890430189669 0.02757895308335622 0.006157685816287994
99 93.54713821411133 0.02838574869632721 0.006426359415054321
100 93.65172867104411 0.028756754597028096 0.006406557559967041
101 93.54380028881133 0.0298872793674469 0.006314320862293244
102 93.57864282466471 0.029303233194351196 0.0063784348964691165
103 93.54104107245803 0.030305790615081787 0.006692185997962952
104 93.55548015236855 0.029678312301635743 0.0063146230578422545
105 93.56082061119378 0.029717696992556254 0.006222049295902252
Early stop at epoch 106
Training Time:9873.257s
